import gradio as gr
import soundfile as sf
import tempfile
import torch
from vieneu_tts import VieNeuTTS

print("‚è≥ ƒêang kh·ªüi ƒë·ªông VieNeu-TTS...")

# Kh·ªüi t·∫°o model
print("üì¶ ƒêang t·∫£i model...")
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"üñ•Ô∏è S·ª≠ d·ª•ng thi·∫øt b·ªã: {device.upper()}")

tts = VieNeuTTS(
    backbone_repo="pnnbao-ump/VieNeu-TTS-1000h",
    backbone_device=device,
    codec_repo="neuphonic/neucodec",
    codec_device=device
)
print("‚úÖ Model ƒë√£ t·∫£i xong!")

# Danh s√°ch gi·ªçng m·∫´u
VOICE_SAMPLES = {
    "Nam 1": {
        "audio": "./sample/id_0001.wav",
        "text": "./sample/id_0001.txt"
    },
    "N·ªØ 1": {
        "audio": "./sample/id_0002.wav",
        "text": "./sample/id_0002.txt"
    },
    "Nam 2": {
        "audio": "./sample/id_0003.wav",
        "text": "./sample/id_0003.txt"
    },
    "N·ªØ 2": {
        "audio": "./sample/id_0004.wav",
        "text": "./sample/id_0004.txt"
    },
    "Nam 3": {
        "audio": "./sample/id_0005.wav",
        "text": "./sample/id_0005.txt"
    },
    "Nam 4": {
        "audio": "./sample/id_0007.wav",
        "text": "./sample/id_0007.txt"
    }
}

def synthesize_speech(text, voice_choice, custom_audio=None, custom_text=None):
    """T·ªïng h·ª£p gi·ªçng n√≥i t·ª´ vƒÉn b·∫£n"""
    try:
        if not text or text.strip() == "":
            return None, "‚ùå Vui l√≤ng nh·∫≠p vƒÉn b·∫£n c·∫ßn t·ªïng h·ª£p"
        
        if len(text) > 250:
            return None, "‚ùå VƒÉn b·∫£n qu√° d√†i! Vui l√≤ng nh·∫≠p t·ªëi ƒëa 250 k√Ω t·ª±. ƒê·ªÉ t·ªïng h·ª£p vƒÉn b·∫£n d√†i h∆°n, vui l√≤ng tham kh·∫£o examples/infer_long_text.py"
        
        # X√°c ƒë·ªãnh reference audio v√† text
        if custom_audio is not None and custom_text:
            ref_audio_path = custom_audio
            ref_text_raw = custom_text
            print("üé® S·ª≠ d·ª•ng gi·ªçng t√πy ch·ªânh")
        elif voice_choice in VOICE_SAMPLES:
            ref_audio_path = VOICE_SAMPLES[voice_choice]["audio"]
            ref_text_path = VOICE_SAMPLES[voice_choice]["text"]
            with open(ref_text_path, "r", encoding="utf-8") as f:
                ref_text_raw = f.read()
            print(f"üé§ S·ª≠ d·ª•ng gi·ªçng: {voice_choice}")
        else:
            return None, "‚ùå Vui l√≤ng ch·ªçn gi·ªçng ho·∫∑c t·∫£i l√™n audio t√πy ch·ªânh"
        
        # Encode v√† t·ªïng h·ª£p
        print(f"üìù ƒêang x·ª≠ l√Ω: {text[:50]}...")
        ref_codes = tts.encode_reference(ref_audio_path)
        
        print(f"üéµ ƒêang t·ªïng h·ª£p gi·ªçng n√≥i tr√™n {device.upper()}...")
        wav = tts.infer(text, ref_codes, ref_text_raw)
        
        # L∆∞u file
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            sf.write(tmp_file.name, wav, 24000)
            output_path = tmp_file.name
        
        print("‚úÖ Ho√†n th√†nh!")
        return output_path, f"‚úÖ T·ªïng h·ª£p th√†nh c√¥ng"
        
    except Exception as e:
        print(f"‚ùå L·ªói: {str(e)}")
        import traceback
        traceback.print_exc()
        return None, f"‚ùå L·ªói: {str(e)}"

# Custom CSS - t·ªëi gi·∫£n
custom_css = """
.gradio-container {
    max-width: 900px !important;
    margin: 0 auto !important;
}
.warning-box {
    background-color: #fef3c7;
    border-left: 4px solid #f59e0b;
    padding: 12px 16px;
    border-radius: 6px;
    margin: 10px 0;
    color: #000000;
}
"""

# T·∫°o giao di·ªán
with gr.Blocks(title="VieNeu-TTS", css=custom_css, theme=gr.themes.Soft()) as demo:
    gr.Markdown("""


    # VieNeu-TTS

    H·ªá th·ªëng t·ªïng h·ª£p ti·∫øng n√≥i ti·∫øng Vi·ªát s·ª≠ d·ª•ng Large Language Model

    **Phi√™n b·∫£n:** VieNeu-TTS-1000h (model m·ªõi nh·∫•t, train tr√™n 1000 gi·ªù d·ªØ li·ªáu)

    [GitHub](https://github.com/pnnbao97/VieNeu-TTS) ‚Ä¢ [Model Card](https://huggingface.co/pnnbao-ump/VieNeu-TTS) ‚Ä¢ [Finetune Guide](https://github.com/pnnbao-ump/VieNeuTTS/blob/main/finetune.ipynb)
    
    """)
    # Main interface
    with gr.Row():

        
        with gr.Column(scale=1):
            
            text_input = gr.Textbox(
                label="VƒÉn b·∫£n",
                placeholder="Nh·∫≠p vƒÉn b·∫£n ti·∫øng Vi·ªát (khuy·∫øn c√°o d∆∞·ªõi 250 k√Ω t·ª±)...",
                lines=5,
                value="Tr√≠ tu·ªá nh√¢n t·∫°o ƒëang c√°ch m·∫°ng h√≥a nhi·ªÅu lƒ©nh v·ª±c, t·ª´ y t·∫ø, gi√°o d·ª•c ƒë·∫øn giao th√¥ng v·∫≠n t·∫£i, mang l·∫°i nh·ªØng gi·∫£i ph√°p th√¥ng minh v√† hi·ªáu qu·∫£."
            )
            
            char_count = gr.Markdown("**142 / 250 k√Ω t·ª±**")
            
            voice_select = gr.Radio(
                choices=list(VOICE_SAMPLES.keys()),
                label="Ch·ªçn gi·ªçng",
                value="Nam 1"
            )
            
            submit_btn = gr.Button("T·ªïng h·ª£p", variant="primary", size="lg")
        
        with gr.Column(scale=1):
            audio_output = gr.Audio(label="K·∫øt qu·∫£", type="filepath")
            status_output = gr.Textbox(label="Tr·∫°ng th√°i", interactive=False, show_label=False)
            
            with gr.Accordion("Gi·ªçng t√πy ch·ªânh", open=False):
                gr.Markdown("""
T·∫£i l√™n file audio v√† nh·∫≠p n·ªôi dung t∆∞∆°ng ·ª©ng. ƒê·ªÉ c√≥ k·∫øt qu·∫£ t·ªët nh·∫•t, n√™n finetune model tr√™n gi·ªçng c·ªßa b·∫°n.
                """)
                custom_audio = gr.Audio(label="File audio (.wav)", type="filepath")
                custom_text = gr.Textbox(
                    label="N·ªôi dung audio",
                    placeholder="Nh·∫≠p ch√≠nh x√°c n·ªôi dung...",
                    lines=2
                )
            gr.HTML("""
            <div class="warning-box" style="color: #000000;">
                ‚ö†Ô∏è Ch√∫ng t√¥i khuy·∫øn c√°o s·ª≠ d·ª•ng ƒëo·∫°n vƒÉn b·∫£n <250 k√Ω t·ª± ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng t·ªët nh·∫•t. 
                N·∫øu mu·ªën t·ªïng h·ª£p vƒÉn b·∫£n d√†i h∆°n, vui l√≤ng tham kh·∫£o code trong examples/infer_long_text.py
            </div>
            """)
    
    # Examples
    with gr.Row():
        gr.Examples(
            examples=[
                ["Tr√≠ tu·ªá nh√¢n t·∫°o ƒëang c√°ch m·∫°ng h√≥a nhi·ªÅu lƒ©nh v·ª±c, t·ª´ y t·∫ø, gi√°o d·ª•c ƒë·∫øn giao th√¥ng v·∫≠n t·∫£i, mang l·∫°i nh·ªØng gi·∫£i ph√°p th√¥ng minh v√† hi·ªáu qu·∫£.", "Nam 1"],
                ["Tr√™n b·∫ßu tr·ªùi xanh th·∫≥m, nh·ªØng ƒë√°m m√¢y tr·∫Øng l·ª≠ng l·ªù tr√¥i nh∆∞ nh·ªØng chi·∫øc thuy·ªÅn nh·ªè ƒëang l∆∞·ªõt nh·∫π theo d√≤ng gi√≥. D∆∞·ªõi m·∫∑t ƒë·∫•t, c√°nh ƒë·ªìng l√∫a v√†ng r·ª±c tr·∫£i d√†i t·ªõi t·∫≠n ch√¢n tr·ªùi, nh·ªØng b√¥ng l√∫a nghi√™ng m√¨nh theo t·ª´ng l√†n gi√≥.", "N·ªØ 2"],
                ["Legacy l√† m·ªôt b·ªô phim ƒë·ªôt ph√° v·ªÅ m·∫∑t √¢m nh·∫°c, quay phim, hi·ªáu ·ª©ng ƒë·∫∑c bi·ªát, v√† t√¥i r·∫•t m·ª´ng v√¨ cu·ªëi c√πng n√≥ c≈©ng ƒë∆∞·ª£c c·∫£ gi·ªõi ph√™ b√¨nh l·∫´n ng∆∞·ªùi h√¢m m·ªô ƒë√°nh gi√° l·∫°i. Ch√∫ng ta ƒë√£ qu√° b·∫•t c√¥ng v·ªõi b·ªô phim n√†y v√†o nƒÉm 2010.", "Nam 4"],
                ["Th·∫≠t ƒë√°ng ng·∫°c nhi√™n! M·∫∑c d√π con ƒë∆∞·ªùng n√†y r·∫•t xa v√† kh√≥ ƒëi, nh∆∞ng v·ªõi s·ª± ki√™n tr√¨ v√† s·ª± ƒë·ªìng l√≤ng c·ªßa t·∫•t c·∫£ m·ªçi ng∆∞·ªùi, ch√∫ng ta ƒë√£ ho√†n th√†nh ƒë∆∞·ª£c c√¥ng vi·ªác s·ª≠a ch·ªØa tr∆∞·ªõc 3 ng√†y so v·ªõi k·∫ø ho·∫°ch ban ƒë·∫ßu, b·∫°n c√≥ tin kh√¥ng?", "N·ªØ 1"],
                ["C√°c b√°c sƒ© ƒëang nghi√™n c·ª©u m·ªôt lo·∫°i vaccine m·ªõi ch·ªëng l·∫°i virus c√∫m m√πa. Th√≠ nghi·ªám l√¢m s√†ng cho th·∫•y ph·∫£n ·ª©ng mi·ªÖn d·ªãch m·∫°nh m·∫Ω v√† √≠t t√°c d·ª•ng ph·ª•.", "Nam 2"],
            ],
            inputs=[text_input, voice_select],
            outputs=[audio_output, status_output],
            fn=synthesize_speech,
            cache_examples=False
        )
    
    # Footer info
    gr.Markdown("""
---

**T√°c gi·∫£:** Ph·∫°m Nguy·ªÖn Ng·ªçc B·∫£o ‚Ä¢ **Model:** VieNeu-TTS-1000h

**L∆∞u √Ω:** N·∫øu mu·ªën s·ª≠ d·ª•ng model c≈© VieNeu-TTS-140h, h√£y thay ƒë·ªïi `backbone_repo` trong m√£ ngu·ªìn

---

### ·ª¶ng h·ªô d·ª± √°n

VieNeu-TTS l√† d·ª± √°n mi·ªÖn ph√≠ v√† m√£ ngu·ªìn m·ªü. Tuy nhi√™n, vi·ªác train model TTS ch·∫•t l∆∞·ª£ng cao tr√™n 1000+ gi·ªù d·ªØ li·ªáu ƒë√≤i h·ªèi ngu·ªìn l·ª±c t√≠nh to√°n ƒë√°ng k·ªÉ.

N·∫øu b·∫°n th·∫•y d·ª± √°n n√†y h·ªØu √≠ch, h√£y c√¢n nh·∫Øc ·ªßng h·ªô:

‚òï [Buy Me a Coffee](https://buymeacoffee.com/pnnbao)

    """)
    
    # Update character count
    def update_char_count(text):
        count = len(text) if text else 0
        color = "#dc2626" if count > 250 else "#374151"
        return f"<span style='color: {color}; font-weight: 500'>{count} / 250 k√Ω t·ª±</span>"
    
    text_input.change(
        fn=update_char_count,
        inputs=[text_input],
        outputs=[char_count]
    )
    
    # Event handler
    submit_btn.click(
        fn=synthesize_speech,
        inputs=[text_input, voice_select, custom_audio, custom_text],
        outputs=[audio_output, status_output]
    )

# Launch
if __name__ == "__main__":
    demo.queue(max_size=20)
    demo.launch(
        share=False,
        server_name="127.0.0.1",
        server_port=7860,
        show_error=True
    )