# VieNeu-TTS

[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue)](https://github.com/pnnbao97/VieNeu-TTS)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-Model-yellow)](https://huggingface.co/pnnbao-ump/VieNeu-TTS-1000h)

<img width="899" height="615" alt="Untitled" src="https://github.com/user-attachments/assets/7eb9b816-6ab7-4049-866f-f85e36cb9c6f" />

**VieNeu-TTS-1000h** is an advanced on-device Vietnamese Text-to-Speech (TTS) model with **instant voice cloning**.  

Trained on ~1000 hours of high-quality Vietnamese speech, this model represents a significant upgrade from VieNeu-TTS-140h with the following improvements:

- **Enhanced pronunciation**: More accurate and stable Vietnamese pronunciation
- **Code-switching support**: Seamless transitions between Vietnamese and English
- **Better voice cloning**: Higher fidelity and speaker consistency
- **Real-time synthesis**: 24 kHz waveform generation on CPU or GPU

Fine-tuned from **NeuTTS Air**, VieNeu-TTS-1000h delivers production-ready speech synthesis fully offline.

**Author:** Pháº¡m Nguyá»…n Ngá»c Báº£o
> ğŸ“¢ Sáº¯p ra máº¯t: Há»— trá»£ GGUF cho CPU!
> ChÃºng tÃ´i Ä‘ang gáº¥p rÃºt hoÃ n thiá»‡n phiÃªn báº£n há»— trá»£ GGUF Ä‘á»ƒ cho phÃ©p mÃ´ hÃ¬nh cháº¡y hiá»‡u quáº£ trÃªn CPU mÃ  khÃ´ng cáº§n GPU máº¡nh.
> PhiÃªn báº£n nÃ y dá»± kiáº¿n sáº½ Ä‘Æ°á»£c ra máº¯t sá»›m, trong 1-2 tuáº§n tá»›i. HÃ£y theo dÃµi kho lÆ°u trá»¯ GitHub Ä‘á»ƒ nháº­n thÃ´ng bÃ¡o má»›i nháº¥t!

---

## âœ¨ Features

- ğŸ™ï¸ High-quality Vietnamese speech at 24â€¯kHz
- ğŸš€ Instant voice cloning using a short reference clip
- ğŸ’» Fully offline inference (no internet required)
- ğŸ¯ Multiple curated reference voices (Southern accent, male & female)
- âš¡ Real-time or faster-than-real-time synthesis on CPU/GPU
- ğŸ–¥ï¸ Ready-to-use Python API, CLI scripts, and a Gradio UI

---

## ğŸ’ Support This Project

**VieNeu-TTS** is a free, open-source project. However, training high-quality TTS models on **1000+ hours of speech data** requires significant computational resources.

If you find this project useful, please consider supporting its development:

<div align="center">

[![Buy Me a Coffee](https://img.shields.io/badge/â˜•_Buy_Me_a_Coffee-FFDD00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://buymeacoffee.com/pnnbao)

</div>

**Your support helps:**

- ğŸ’° **GPU Training Costs**: Training on 1000+ hours costs thousands of dollars in compute
- ğŸš€ **New Features**: Emotion control, speaking styles, GGUF quantization
- ğŸ“Š **Dataset Expansion**: Collecting more diverse Vietnamese voices (North, Central, South)
- ğŸ¯ **Quality Improvements**: Better pronunciation, naturalness, and voice cloning fidelity
- ğŸŒ **Bilingual Support**: Vietnamese + English code-switching capabilities
- ğŸ”§ **Maintenance**: Bug fixes, updates, and community support

<div align="center">

*Every contribution, big or small, makes a real difference!*  
*Thank you for supporting Vietnamese AI development!* ğŸ‡»ğŸ‡³ğŸ™

</div>

---

## ğŸ”¬ Model Overview

- **Backbone:** Qwen 0.5B LLM (chat template)
- **Audio codec:** NeuCodec (torch implementation; ONNX & quantized variants supported)
- **Context window:** 2â€¯048 tokens shared by prompt text and speech tokens
- **Output watermark:** Enabled by default
- **Training data:**  
  - [VieNeu-TTS-1000h](https://huggingface.co/datasets/pnnbao-ump/VieNeu-TTS-1000h) â€” 443,641 curated Vietnamese samples  

---

## ğŸ Getting Started

> **ğŸ“º HÆ°á»›ng dáº«n cÃ i Ä‘áº·t báº±ng tiáº¿ng Viá»‡t**: Xem video chi tiáº¿t táº¡i [Facebook Reel](https://www.facebook.com/reel/1362972618623766)

### 1. Clone the repository

```bash
git clone https://github.com/pnnbao97/VieNeu-TTS.git
cd VieNeu-TTS
```

### 2. Install eSpeak NG (required by phonemizer)

Follow the [official installation guide](https://github.com/espeak-ng/espeak-ng/blob/master/docs/guide.md). Common commands:

```bash
# macOS
brew install espeak

# Ubuntu / Debian
sudo apt install espeak-ng

# Arch Linux
paru -S aur/espeak-ng

# Windows
# Download installer from https://github.com/espeak-ng/espeak-ng/releases
# Default path: C:\Program Files\eSpeak NG\
# VieNeu-TTS auto-detects this path.
```

**macOS tips**
- If the phonemizer cannot find the library, set `PHONEMIZER_ESPEAK_LIBRARY` to the `.dylib` path.
- Validate installation with: `echo 'test' | espeak-ng -x -q --ipa -v vi`

### 3. Install Python dependencies (Python â‰¥ 3.11)

```bash
python -m venv .venv
source .venv/bin/activate        # or .venv\Scripts\activate on Windows
pip install -r requirements.txt

# Optional alternatives
uv pip install -r requirements.txt
pip install -e .
```

If you intend to run on GPU, install the matching CUDA build of PyTorch:

```bash
# Example for CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

---

## ğŸ“¦ Project Structure

```
VieNeu-TTS/
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ infer_long_text.py     # CLI for long-form synthesis (chunked)
â”‚   â””â”€â”€ sample_long_text.txt   # Example paragraph for testing
â”œâ”€â”€ gradio_app.py              # Local Gradio demo
â”œâ”€â”€ main.py                    # Basic batch inference script
â”œâ”€â”€ output_audio/              # Generated audio (created when running scripts)
â”œâ”€â”€ sample/                    # Reference voices (audio + transcript pairs)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ normalize_text.py      # Vietnamese text normalization pipeline
â”œâ”€â”€ vieneu_tts/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ vieneu_tts.py          # Core VieNeuTTS implementation
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ pyproject.toml
```

---

## ğŸš€ Quickstart

## Quick Usage (Python)

```python
from vieneu_tts import VieNeuTTS
import soundfile as sf
import os

input_texts = [
    "CÃ¡c khÃ³a há»c trá»±c tuyáº¿n Ä‘ang giÃºp há»c sinh tiáº¿p cáº­n kiáº¿n thá»©c má»i lÃºc má»i nÆ¡i. GiÃ¡o viÃªn sá»­ dá»¥ng video, bÃ i táº­p tÆ°Æ¡ng tÃ¡c vÃ  tháº£o luáº­n trá»±c tuyáº¿n Ä‘á»ƒ nÃ¢ng cao hiá»‡u quáº£ há»c táº­p.",

    "CÃ¡c nghiÃªn cá»©u vá» bá»‡nh Alzheimer cho tháº¥y tÃ¡c dá»¥ng tÃ­ch cá»±c cá»§a cÃ¡c bÃ i táº­p trÃ­ nÃ£o vÃ  cháº¿ Ä‘á»™ dinh dÆ°á»¡ng lÃ nh máº¡nh, giÃºp giáº£m tá»‘c Ä‘á»™ suy giáº£m trÃ­ nhá»› á»Ÿ ngÆ°á»i cao tuá»•i.",

    "Má»™t tiá»ƒu thuyáº¿t trinh thÃ¡m hiá»‡n Ä‘áº¡i dáº«n dáº¯t Ä‘á»™c giáº£ qua nhá»¯ng tÃ¬nh tiáº¿t phá»©c táº¡p, bÃ­ áº©n, káº¿t há»£p yáº¿u tá»‘ tÃ¢m lÃ½ sÃ¢u sáº¯c khiáº¿n ngÆ°á»i Ä‘á»c luÃ´n há»“i há»™p theo dÃµi diá»…n biáº¿n cÃ¢u chuyá»‡n.",

    "CÃ¡c nhÃ  khoa há»c nghiÃªn cá»©u gen ngÆ°á»i phÃ¡t hiá»‡n nhá»¯ng Ä‘á»™t biáº¿n má»›i liÃªn quan Ä‘áº¿n bá»‡nh di truyá»n. Äiá»u nÃ y giÃºp nÃ¢ng cao kháº£ nÄƒng cháº©n Ä‘oÃ¡n vÃ  Ä‘iá»u trá»‹.",
]

output_dir = "./output_audio"
os.makedirs(output_dir, exist_ok=True)

def main(backbone="pnnbao-ump/VieNeu-TTS-1000h", codec="neuphonic/neucodec"):
    """
    In the sample directory, there are 7 wav files and 7 txt files with matching names.
    These are pre-prepared reference files for testing:
    - id_0001.wav + id_0001.txt
    - id_0002.wav + id_0002.txt
    - id_0003.wav + id_0003.txt
    - id_0004.wav + id_0004.txt
    - id_0005.wav + id_0005.txt
    - id_0006.wav + id_0006.txt
    - id_0007.wav + id_0007.txt
    
    Odd numbers = Male voices
    Even numbers = Female voices
    
    Note: The model can clone any voice you provide (with corresponding text).
    However, quality may not match the sample files. For best results, finetune
    the model on your target voice. See finetune guide at:
    https://github.com/pnnbao-ump/VieNeuTTS/blob/main/finetune.ipynb
    """
    # Male voice (South accent)
    ref_audio_path = "./sample/id_0001.wav"
    ref_text_path = "./sample/id_0001.txt"
    
    # Female voice (South accent) - uncomment to use
    # ref_audio_path = "./sample/id_0002.wav"
    # ref_text_path = "./sample/id_0002.txt"

    ref_text_raw = open(ref_text_path, "r", encoding="utf-8").read()
    
    if not ref_audio_path or not ref_text_raw:
        print("No reference audio or text provided.")
        return None

    # Initialize VieNeuTTS-1000h
    tts = VieNeuTTS(
        backbone_repo=backbone,
        backbone_device="cuda",
        codec_repo=codec,
        codec_device="cuda"
    )

    print("Encoding reference audio...")
    ref_codes = tts.encode_reference(ref_audio_path)

    # Generate speech for all input texts
    for i, text in enumerate(input_texts, 1):
        print(f"Generating audio {i}/{len(input_texts)}: {text[:50]}...")
        wav = tts.infer(text, ref_codes, ref_text_raw)
        output_path = os.path.join(output_dir, f"output_{i}.wav")
        sf.write(output_path, wav, 24000)
        print(f"âœ“ Saved to {output_path}")

if __name__ == "__main__":
    main()
```

### CLI example (`main.py`)

```bash
python main.py
```

This script runs several normalized sentences using the bundled sample voice and writes `output_*.wav` files under `output_audio/`.

### Gradio web demo
[<img width="600" height="595" alt="VieNeu-TTS" src="https://github.com/user-attachments/assets/66c098c4-d184-4e7a-826a-ba8c6c556fab" />](https://github.com/user-attachments/assets/5ad53bc9-e816-41a7-9474-ea470b1cbfdd)

```bash
python gradio_app.py
```

Then open `http://127.0.0.1:7860` to:

- Pick one of six reference voices
- Upload your own reference audio + transcript
- Enter up to 250 characters per request (recommended)
- Preview or download the synthesized audio

### Long-text helper

`examples/infer_long_text.py` chunks long passages into â‰¤256-character segments (prefers sentence boundaries) and synthesizes them sequentially.

```bash
python -m examples.infer_long_text.py \
  --text-file examples/sample_long_text.txt \
  --ref-audio sample/id_0001.wav \
  --ref-text sample/id_0001.txt \
  --output output_audio/sample_long_text.wav
```

[ğŸµ Listen to sample (MP3)](https://github.com/user-attachments/files/23436562/longtext.mp3)

Use `--text "raw paragraph here"` to infer without creating a file.

---

## ğŸ”ˆ Reference Voices (`sample/`)

| File      | Gender | Accent | Description        |
|-----------|--------|--------|--------------------|
| id_0001   | Male   | South  | Male voice 1       |
| id_0002   | Female | South  | Female voice 1     |
| id_0003   | Male   | South  | Male voice 2       |
| id_0004   | Female | South  | Female voice 2     |
| id_0005   | Male   | South  | Male voice 3       |
| id_0007   | Male   | South  | Male voice 4       |

Odd IDs correspond to male voices; even IDs correspond to female voices.

---

## âœ… Best Practices & Limits

- Keep each inference request â‰¤250 characters to stay within the 2â€¯048-token context window (reference speech tokens also consume context).
- Normalize both the target text and the reference transcript before inference (built-in scripts already do this).
- Trim reference audio to ~3â€“5 seconds for faster processing and consistent quality.
- For long articles, split by paragraph/sentence and stitch the outputs â€“ use `examples/infer_long_text.py`.
- Always obtain consent before cloning someoneâ€™s voice.

---

## âš ï¸ Troubleshooting

| Issue | Likely cause | How to fix |
|-------|--------------|------------|
| `ValueError: Could not find libespeak...` | eSpeak NG is missing or the path is incorrect | Install eSpeak NG and set `PHONEMIZER_ESPEAK_LIBRARY` if required |
| `401 Unauthorized` when downloading `facebook/w2v-bert-2.0` | Invalid or stale Hugging Face token in the environment | Run `huggingface-cli login --token â€¦` or remove `HF_TOKEN` to use anonymous access |
| `CUDA out of memory` | GPU VRAM is insufficient | Switch to CPU (`backbone_device="cpu"` & `codec_device="cpu"`) or use a quantized checkpoint |
| `No valid speech tokens found` | Prompt too long, empty text, or poor reference clip | Shorten the input, double-check normalization, or pick another reference sample |

---

## ğŸ“š References

- [GitHub Repository](https://github.com/pnnbao97/VieNeu-TTS)  
- [Hugging Face Model Card](https://huggingface.co/pnnbao-ump/VieNeu-TTS)  
- [NeuTTS Air base model](https://huggingface.co/neuphonic/neutts-air)  
- [Fine-tuning guide](https://github.com/pnnbao-ump/VieNeuTTS/blob/main/finetune.ipynb)  
- [VieNeuCodec dataset](https://huggingface.co/datasets/pnnbao-ump/VieNeuCodec-dataset)

---

## ğŸ“„ License

Apache License 2.0

---

## ğŸ“‘ Citation

```bibtex
@misc{vieneutts2025,
  title        = {VieNeu-TTS: Vietnamese Text-to-Speech with Instant Voice Cloning},
  author       = {Pham Nguyen Ngoc Bao},
  year         = {2025},
  publisher    = {Hugging Face},
  howpublished = {\url{https://huggingface.co/pnnbao-ump/VieNeu-TTS}}
}
```

Please also cite the base model:

```bibtex
@misc{neuttsair2025,
  title        = {NeuTTS Air: On-Device Speech Language Model with Instant Voice Cloning},
  author       = {Neuphonic},
  year         = {2025},
  publisher    = {Hugging Face},
  howpublished = {\url{https://huggingface.co/neuphonic/neutts-air}}
}
```

---

## ğŸ¤ Contributing

Contributions are welcome!

1. Fork the repository  
2. Create a feature branch: `git checkout -b feature/amazing-feature`  
3. Commit your changes: `git commit -m "Add amazing feature"`  
4. Push the branch: `git push origin feature/amazing-feature`  
5. Open a pull request

---

## ğŸ“ Support

- GitHub Issues: [github.com/pnnbao97/VieNeu-TTS/issues](https://github.com/pnnbao97/VieNeu-TTS/issues)  
- Hugging Face: [huggingface.co/pnnbao-ump](https://huggingface.co/pnnbao-ump)  
- Facebook: [Pháº¡m Nguyá»…n Ngá»c Báº£o](https://www.facebook.com/bao.phamnguyenngoc.5)

---

## ğŸ™ Acknowledgements

This project builds upon [NeuTTS Air](https://huggingface.co/neuphonic/neutts-air) by Neuphonic. Huge thanks to the team for open-sourcing such a powerful base model.

---

**Made with â¤ï¸ for the Vietnamese TTS community**














